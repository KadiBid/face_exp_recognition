{"cells":[{"cell_type":"code","execution_count":null,"id":"N31dcV0oDy_V","metadata":{"id":"N31dcV0oDy_V"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","%cd '/content/drive/MyDrive/Colab Notebooks/final_project'"]},{"cell_type":"code","execution_count":null,"id":"bd394f20","metadata":{"id":"bd394f20"},"outputs":[],"source":["import os\n","import numpy as np\n","import pandas as pd\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import MinMaxScaler, LabelBinarizer\n","\n","import tensorflow as tf\n","from tensorflow.keras import Sequential\n","from tensorflow.keras.layers import Conv2D, BatchNormalization, MaxPooling2D, Dropout, Flatten, Dense, GlobalAveragePooling2D\n","from tensorflow.keras.optimizers.legacy import Adam\n","from tensorflow.keras.callbacks import TensorBoard\n","from tensorflow.keras.applications import MobileNetV2, ResNet50\n","from tensorflow.keras.models import Model\n","\n","from PIL import Image"]},{"cell_type":"code","execution_count":null,"id":"Z40fGHPS4UtN","metadata":{"id":"Z40fGHPS4UtN"},"outputs":[],"source":["# Load dataset images into the DataFrame and convert into RGB (required by MobileNetV2)\n","\n","dataset = []\n","\n","for emotion in os.listdir('dataset'):\n","    if os.path.isdir(f'dataset/{emotion}'):\n","        for image_filename in os.listdir(f'dataset/{emotion}'):\n","          image = Image.open(f'dataset/{emotion}/{image_filename}').convert(\"RGB\")\n","          pixels = np.array(image).astype(float)\n","          dataset.append((pixels, emotion))\n","\n","df = pd.DataFrame(dataset, columns=['pixels', 'emotion'])"]},{"cell_type":"code","execution_count":null,"id":"xp8NChn1_cL8","metadata":{"id":"xp8NChn1_cL8"},"outputs":[],"source":["# Normalizacion of the data.\n","\n","X = np.array((df['pixels']/255).values.tolist())\n","Y = LabelBinarizer().fit_transform(df['emotion'])"]},{"cell_type":"code","execution_count":null,"id":"oxcjZco2_et5","metadata":{"id":"oxcjZco2_et5"},"outputs":[],"source":["# Split dataset into train and test data.\n","\n","X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)"]},{"cell_type":"code","execution_count":null,"id":"Bhsvl25o_8vA","metadata":{"id":"Bhsvl25o_8vA"},"outputs":[],"source":["# Attributes for input (images width, high and channel) and output (number of labels).\n","\n","_, IMAGE_WIDTH, IMAGE_HEIGHT, NUM_CHANNELS = X.shape\n","_, NUM_LABELS = Y.shape"]},{"cell_type":"code","execution_count":null,"id":"9c7fd178","metadata":{},"outputs":[],"source":["#Create a VGG model.\n","\n","base_model = VGG16(input_shape=(IMAGE_WIDTH, IMAGE_HEIGHT, NUM_CHANNELS),\n","                      include_top=False, \n","                      weights='imagenet')\n","\n","#base_model.trainable = False\n","\n","modelVGG = Sequential([\n","    base_model,\n","    GlobalAveragePooling2D(),\n","    Dense(256, activation=\"relu\"),\n","    Dropout(0.5),\n","    Dense(NUM_LABELS, activation=\"softmax\")\n","])\n","\n","# Compilar el modelo\n","modelVGG.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"]},{"cell_type":"code","execution_count":null,"id":"8fb1b14a","metadata":{},"outputs":[],"source":["# Train the VGG model\n","\n","modelVGG.fit(X_train, Y_train,\n","             batch_size=64, \n","             epochs=25, \n","             validation_data=(X_test, Y_test),\n","             callbacks=[TensorBoard(log_dir=\"logs/modelVGG\")])"]},{"cell_type":"code","execution_count":null,"id":"02524ac6","metadata":{},"outputs":[],"source":["score, acc = modelVGG.evaluate(X_test, Y_test, batch_size=100)\n","print('Test score:', score)\n","print(\"Test accuracy:\", acc)"]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","private_outputs":true,"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"core","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.6 (main, Oct  7 2022, 15:17:23) [Clang 12.0.0 ]"},"vscode":{"interpreter":{"hash":"36e5de6d90be7b7a3a3ddd9c65185cb7f794e19b41a32400abf9d42fc8f23759"}}},"nbformat":4,"nbformat_minor":5}
